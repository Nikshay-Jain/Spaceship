{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b9b57a",
   "metadata": {},
   "source": [
    "## Analysing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708cf5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4c917d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "y_train_raw = train_raw.pop('Transported')\n",
    "y_test = pd.read_csv('sample_submission.csv')\n",
    "y_test = y_test['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66528306",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['HomePlanet'].fillna('Earth', inplace = True)\n",
    "train_raw['CryoSleep'].fillna(0, inplace = True)\n",
    "train_raw['Destination'].fillna('TRAPPIST-1e', inplace = True)\n",
    "train_raw['Age'].fillna(train_raw['Age'].median(), inplace = True)\n",
    "train_raw['RoomService'].fillna(train_raw['RoomService'].median(), inplace = True)\n",
    "\n",
    "#assuming all had food here and price = mean of available bills ie total - 0s - NaNs\n",
    "tot = train_raw.shape[0]\n",
    "train_raw['FoodCourt'].fillna((train_raw['FoodCourt'].mean() * tot / (tot - sum(train_raw['FoodCourt']==0) - sum(train_raw['FoodCourt'].isna()==True))), inplace = True)\n",
    "train_raw['ShoppingMall'].fillna((train_raw['ShoppingMall'].mean() * tot / (tot - sum(train_raw['ShoppingMall']==0) - sum(train_raw['ShoppingMall'].isna()==True))), inplace = True)\n",
    "train_raw['Spa'].fillna((train_raw['Spa'].mean() * tot / (tot - sum(train_raw['Spa']==0) - sum(train_raw['Spa'].isna()==True))), inplace = True)\n",
    "train_raw['VRDeck'].fillna((train_raw['VRDeck'].mean() * tot / (tot - sum(train_raw['VRDeck']==0) - sum(train_raw['VRDeck'].isna()==True))), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1e0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['CryoSleep'] = train_raw['CryoSleep'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "596ade36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8693 non-null   object \n",
      " 2   CryoSleep     8693 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8693 non-null   object \n",
      " 5   Age           8693 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8693 non-null   float64\n",
      " 8   FoodCourt     8693 non-null   float64\n",
      " 9   ShoppingMall  8693 non-null   float64\n",
      " 10  Spa           8693 non-null   float64\n",
      " 11  VRDeck        8693 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 883.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c201a",
   "metadata": {},
   "source": [
    "### Stratified Shuffle Split data to get CV set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e80320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training and cross-validation sets\n",
    "for train_index, cv_index in stratified_split.split(train_raw, y_train_raw):\n",
    "    train, cv = train_raw.iloc[train_index], train_raw.iloc[cv_index]\n",
    "    y_train, y_cv = y_train_raw.iloc[train_index], y_train_raw.iloc[cv_index]\n",
    "    \n",
    "train = train.reset_index()\n",
    "y_train = y_train.reset_index()\n",
    "cv = cv.reset_index()\n",
    "y_cv = y_cv.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa10d671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586</td>\n",
       "      <td>3857_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>E/230/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.127559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eltard Dreamspric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7173</td>\n",
       "      <td>7650_05</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1242/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tera Palmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8559</td>\n",
       "      <td>9139_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1766/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>410.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Poselk Paste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6528</td>\n",
       "      <td>6894_03</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1319/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Risps Hacle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7934</td>\n",
       "      <td>8471_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/556/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>66.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Bosonon Metiveal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>3749</td>\n",
       "      <td>4008_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/760/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anamse Cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>1637</td>\n",
       "      <td>1733_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/344/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevey Chanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>5820</td>\n",
       "      <td>6158_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/996/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dawne Jacobbinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>5757</td>\n",
       "      <td>6102_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1165/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>Jilley Figuez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>4135</td>\n",
       "      <td>4411_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/721/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>37.0</td>\n",
       "      <td>False</td>\n",
       "      <td>715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alendy Parsoney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1739 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index PassengerId HomePlanet CryoSleep     Cabin    Destination   Age  \\\n",
       "0      3586     3857_01     Europa      True   E/230/P    55 Cancri e  34.0   \n",
       "1      7173     7650_05      Earth      True  G/1242/S    TRAPPIST-1e   4.0   \n",
       "2      8559     9139_01       Mars     False  F/1766/S    TRAPPIST-1e  25.0   \n",
       "3      6528     6894_03       Mars     False  F/1319/S    TRAPPIST-1e  12.0   \n",
       "4      7934     8471_01     Europa     False   E/556/S    55 Cancri e  66.0   \n",
       "...     ...         ...        ...       ...       ...            ...   ...   \n",
       "1734   3749     4008_01       Mars      True   F/760/S    TRAPPIST-1e  33.0   \n",
       "1735   1637     1733_01      Earth     False   F/344/P    TRAPPIST-1e  15.0   \n",
       "1736   5820     6158_01      Earth      True   G/996/S  PSO J318.5-22  14.0   \n",
       "1737   5757     6102_01      Earth     False  F/1165/S  PSO J318.5-22  26.0   \n",
       "1738   4135     4411_01      Earth     False   G/721/S  PSO J318.5-22  37.0   \n",
       "\n",
       "        VIP  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "0     False          0.0        0.0    521.127559     0.0     0.0   \n",
       "1     False          0.0        0.0      0.000000     0.0     0.0   \n",
       "2     False        410.0       32.0     14.000000  1239.0    10.0   \n",
       "3       NaN          0.0        0.0      0.000000     0.0     0.0   \n",
       "4      True          0.0     1828.0      1.000000  1873.0    45.0   \n",
       "...     ...          ...        ...           ...     ...     ...   \n",
       "1734  False          0.0        0.0      0.000000     0.0     0.0   \n",
       "1735  False       1336.0      108.0      0.000000     0.0     0.0   \n",
       "1736  False          0.0        0.0      0.000000     0.0     0.0   \n",
       "1737  False        104.0        0.0      0.000000   280.0   216.0   \n",
       "1738  False        715.0        0.0     54.000000     0.0     0.0   \n",
       "\n",
       "                   Name  \n",
       "0     Eltard Dreamspric  \n",
       "1           Tera Palmes  \n",
       "2          Poselk Paste  \n",
       "3           Risps Hacle  \n",
       "4      Bosonon Metiveal  \n",
       "...                 ...  \n",
       "1734         Anamse Cha  \n",
       "1735      Stevey Chanan  \n",
       "1736  Dawne Jacobbinson  \n",
       "1737      Jilley Figuez  \n",
       "1738    Alendy Parsoney  \n",
       "\n",
       "[1739 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "855ccc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Name', axis = 1)\n",
    "train = train.drop('PassengerId', axis = 1)\n",
    "train = train.drop('Cabin', axis = 1)\n",
    "train = train.drop('index', axis = 1)\n",
    "y_train = y_train.drop('index', axis = 1)\n",
    "cv = cv.drop('index', axis = 1)\n",
    "y_cv = y_cv.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2701150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6949</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6951</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6952</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6954 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transported\n",
       "0           True\n",
       "1           True\n",
       "2          False\n",
       "3           True\n",
       "4          False\n",
       "...          ...\n",
       "6949        True\n",
       "6950       False\n",
       "6951        True\n",
       "6952        True\n",
       "6953        True\n",
       "\n",
       "[6954 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype(str)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ee4e6",
   "metadata": {},
   "source": [
    "Useless plot but resembles Earth's Magnetic field if plotted: train.Cabin.value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "pd.plotting.scatter_matrix(train[cols], figsize = (10,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133154a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(bins = 25, figsize = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.HomePlanet.value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe67f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CryoSleep.value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7027682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Destination.value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VIP.value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    print(col)\n",
    "    print(sum(train[col].isna()==True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2c474",
   "metadata": {},
   "source": [
    "## Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79732109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VocabularyListCategoricalColumn(key='HomePlanet', vocabulary_list=('Earth', 'Europa', 'Mars'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='Destination', vocabulary_list=('TRAPPIST-1e', 'PSO J318.5-22', '55 Cancri e'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='VIP', vocabulary_list=(False, True, nan), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='CryoSleep', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='RoomService', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='FoodCourt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ShoppingMall', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Spa', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='VRDeck', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "columns = train.columns.to_numpy()\n",
    "\n",
    "categorial_columns = [\"HomePlanet\", \"Destination\", \"VIP\"]\n",
    "numeric_columns = [\"CryoSleep\", \"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "feature_columns = []\n",
    "\n",
    "for feature in categorial_columns:\n",
    "    vocab = train[feature].unique()               #gets the unique values in the columns\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature,vocab))\n",
    "    \n",
    "for feature in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature))\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de22702",
   "metadata": {},
   "source": [
    "## Input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "842374a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, epochs = 10, shuffle = True, batch_size=32):\n",
    "    def input_fn():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))    #transforms pandas dataframe to tf.data.Dataset using input parameters and the y-labels.\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)                                             #shuffles the data set\n",
    "        ds = ds.batch(batch_size).repeat(epochs)                              #splits dataset into batches and repeats the process epoch no of times\n",
    "        return ds\n",
    "    return input_fn                                                           #returns the function object itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40e493",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edd47144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\NIKSHA~1\\AppData\\Local\\Temp\\tmpns4y102r\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\NIKSHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpns4y102r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# classifier = tf.estimator.DNNClassifier(feature_columns = feature_columns, hidden_units = [30,10], n_classes = 2)\n",
    "# There should be 2 Hidden layers with 30 and 10 neurons which need to classify an input among 2 fixed outputs\n",
    "lin_est = tf.estimator.LinearClassifier(feature_columns = feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9c08692",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(train, y_train)                      #trains the data set\n",
    "# eval_input_fn = make_input_fn(cv, y_cv, epochs=1, shuffle = False)  #passing test data so no need to shuffle or have mult epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e56f29e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:507\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    504\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    508\u001b[0m     element,\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6949    False\n6950    False\n6951    False\n6952    False\n6953    False\nName: VIP, Length: 6954, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlin_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[38;5;241m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss for final step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1212\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m   training_util\u001b[38;5;241m.\u001b[39m_get_or_create_global_step_read(g)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m features, labels, input_hooks \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1212\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_features_and_labels_from_input_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1213\u001b[0m worker_hooks\u001b[38;5;241m.\u001b[39mextend(input_hooks)\n\u001b[0;32m   1214\u001b[0m estimator_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[0;32m   1215\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1048\u001b[0m, in \u001b[0;36mEstimator._get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_features_and_labels_from_input_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_fn, mode):\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m estimator_util\u001b[38;5;241m.\u001b[39mparse_input_fn_result(\n\u001b[1;32m-> 1048\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_input_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1141\u001b[0m, in \u001b[0;36mEstimator._call_input_fn\u001b[1;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[0;32m   1139\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_context\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_context\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m-> 1141\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minput_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m, in \u001b[0;36mmake_input_fn.<locals>.input_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_fn\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m#transforms pandas dataframe to tf.data.Dataset using input parameters and the y-labels.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m      5\u001b[0m         ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)                                             \u001b[38;5;66;03m#shuffles the data set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:830\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[1;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 109\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1633\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1635\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1639\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1642\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1645\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:344\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    342\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    343\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 344\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    282\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    283\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n\u001b[0;32m    284\u001b[0m tensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mCopyFrom(\n\u001b[1;32m--> 285\u001b[0m     \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_tensor_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    288\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    289\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:623\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    622\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElement type not supported in TensorProto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 623\u001b[0m \u001b[43mappend_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_proto\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36mSlowAppendObjectArrayToTensorProto\u001b[1;34m(tensor_proto, proto_values)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend([compat\u001b[38;5;241m.\u001b[39mas_bytes(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values])\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend([\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values])\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:85\u001b[0m, in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bytes_or_text\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected binary or unicode string, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     86\u001b[0m                   (bytes_or_text,))\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got False"
     ]
    }
   ],
   "source": [
    "lin_est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857aaad",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c95992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:507\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    504\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    508\u001b[0m     element,\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6949    False\n6950    False\n6951    False\n6952    False\n6953    False\nName: VIP, Length: 6954, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Steps means go through the dataset untill 5000 inputs have been verified\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[38;5;241m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss for final step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1212\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m   training_util\u001b[38;5;241m.\u001b[39m_get_or_create_global_step_read(g)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m features, labels, input_hooks \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1212\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_features_and_labels_from_input_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1213\u001b[0m worker_hooks\u001b[38;5;241m.\u001b[39mextend(input_hooks)\n\u001b[0;32m   1214\u001b[0m estimator_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[0;32m   1215\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1048\u001b[0m, in \u001b[0;36mEstimator._get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_features_and_labels_from_input_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_fn, mode):\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m estimator_util\u001b[38;5;241m.\u001b[39mparse_input_fn_result(\n\u001b[1;32m-> 1048\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_input_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1141\u001b[0m, in \u001b[0;36mEstimator._call_input_fn\u001b[1;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[0;32m   1139\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_context\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_context\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m-> 1141\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minput_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain(input_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43minput_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Steps means go through the dataset untill 5000 inputs have been verified\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36minput_fn\u001b[1;34m(features, labels, training, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_fn\u001b[39m(features, labels, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m      4\u001b[0m         ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat()\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:830\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[1;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 109\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1633\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1635\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1639\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1642\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1645\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:344\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    342\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    343\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 344\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    282\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    283\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n\u001b[0;32m    284\u001b[0m tensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mCopyFrom(\n\u001b[1;32m--> 285\u001b[0m     \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_tensor_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    288\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    289\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:623\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    622\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElement type not supported in TensorProto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 623\u001b[0m \u001b[43mappend_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_proto\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36mSlowAppendObjectArrayToTensorProto\u001b[1;34m(tensor_proto, proto_values)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend([compat\u001b[38;5;241m.\u001b[39mas_bytes(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values])\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSlowAppendObjectArrayToTensorProto\u001b[39m(tensor_proto, proto_values):\n\u001b[1;32m--> 190\u001b[0m   tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend([\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values])\n",
      "File \u001b[1;32mc:\\users\\nikshay jain\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:85\u001b[0m, in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bytes_or_text\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected binary or unicode string, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     86\u001b[0m                   (bytes_or_text,))\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got False"
     ]
    }
   ],
   "source": [
    "classifier.train(input_fn = lambda: input_fn(train, y_train), steps = 5000)\n",
    "# Steps means go through the dataset untill 5000 inputs have been verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99038a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.evaluate(input_fn = lambda: input_fn(test, y_test,training = False))\n",
    "# No steps as model needs to traverse only once and no training mode so no shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc660ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a6c22d",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
